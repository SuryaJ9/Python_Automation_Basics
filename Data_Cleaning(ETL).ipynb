{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546ed058-1e4a-4761-a5b4-567ee2a00737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Customers: ['Alice', 'Bob', 'Charlie', 'David']\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Cleaning Customer Names from CSV Data.\n",
    "\n",
    "Scenario: You've received dataset from a vendor.\n",
    "It contains inconsistent formatting(extra spaces, wrong casing). \n",
    "you need to standardize it before loading into Azure SQL Database.\n",
    "\n",
    "'''\n",
    "\n",
    "raw_customer = [\" aLICE \",\" BoB \", \"CHARLIE \", \" david \"]\n",
    "\n",
    "# clean & format: strip spaces + capitalize\n",
    "cleaned_customers = list(map(lambda x: x.strip().capitalize(), raw_customer))\n",
    "\n",
    "print(\"Cleaned Customers:\",cleaned_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1433e-8cac-45e6-9f1a-417649017f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Every Data Engineer follow this before load into the data ware house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0b7ede-716f-444b-991e-1eef243af986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed API logic: [{'endpoint': '/fetch_data', 'status': 500}, {'endpoint': '/logout', 'status': 500}]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Use Case 2: Filtering Failed API Logs\n",
    "\n",
    "Scenario: you collect daily logs from APIs and must extract only failed ones for debugging.\n",
    "'''\n",
    "api_logs = [\n",
    "    {\"endpoint\":\"/login\",\"status\":200},\n",
    "    {\"endpoint\":\"/fetch_data\",\"status\":500},\n",
    "    {\"endpoint\":\"/update_user\",\"status\":200},\n",
    "    {\"endpoint\":\"/logout\",\"status\":500}\n",
    "]\n",
    "\n",
    "# Filter failed logs (status code >= 400).\n",
    "\n",
    "failed_logs = list(filter(lambda log: log['status'] >= 400, api_logs))\n",
    "print(\"Failed API logic:\", failed_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a29c9e-b8a6-4f9f-b283-0f0ef47089f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Real world concepts:\n",
    "## Monitoring & filtering error events from system logs before alerting engineers(common in productions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cacbbde-e6bd-4de0-b2c8-51b4c42bbcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Salary Data: [{'name': 'Alice', 'salary_usd': 50000, 'salary_inr': 4150000}, {'name': 'Bob', 'salary_usd': 60000, 'salary_inr': 4980000}, {'name': 'Surya', 'salary_usd': 80000, 'salary_inr': 6640000}]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "usecase 3: Salary Conversion in ETL.\n",
    "Scenarios:\n",
    "HR Provides salary data in USD; your job is to convert it to INR before saving into Azure Blob Storage.\n",
    "\n",
    "'''\n",
    "\n",
    "employee_data = [\n",
    "    {\"name\":\"Alice\",\"salary_usd\":50000},\n",
    "    {\"name\":\"Bob\",\"salary_usd\":60000},\n",
    "    {\"name\":\"Surya\",\"salary_usd\":80000}\n",
    "]\n",
    "\n",
    "# Convert to INR using map\n",
    "usd_to_INR = 83\n",
    "converted = list(map(lambda e: {**e,\"salary_inr\": e[\"salary_usd\"] * usd_to_INR}, employee_data))\n",
    "print(\"Converted Salary Data:\", converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab115396-4122-4167-9ddf-e81818bc4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Real-world Concept:\n",
    "# Transformation step during ETL (Extract -> Transform -> Load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82facf50-3c6a-4fce-8140-c8b058234892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Users: [{'users': 'Ram', 'sessions': 6}, {'users': 'Raj', 'sessions': 7}]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Usecase 4: Identify Active Users \n",
    "Scenario: You're cleaning user engagement data from a website. \n",
    "you must filter users who have more then 5 active sessions.\n",
    "'''\n",
    "\n",
    "user_sessions = [\n",
    "    {\"users\": \"Alice\",\"sessions\":3},\n",
    "    {\"users\": \"Bob\",\"sessions\":4},\n",
    "    {\"users\": \"Ram\",\"sessions\":6},\n",
    "    {\"users\": \"Raj\",\"sessions\":7}\n",
    "]\n",
    "\n",
    "# Filter active users\n",
    "active_users = list(filter(lambda x: x['sessions'] > 5, user_sessions))\n",
    "print(\"Active Users:\", active_users)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3370e8f7-949d-4fa9-b1cc-143a71712119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Valid Readings ( Fahrenheit): [101.3, 83.3, 89.6]\n"
     ]
    }
   ],
   "source": [
    "## Use Case 5:\n",
    "## CLean IoT Sensor Data\n",
    "'''\n",
    "Scenario:\n",
    "IoT sensors stream temperature readings, \n",
    "but some are invalid( None or Negatiive). \n",
    "you must filter valid readings and convert to Fahrenheit.\n",
    "'''\n",
    "\n",
    "sensor_data = [38.5,None, -5, 28.5, 32.0, None]\n",
    "\n",
    "# Filter valid readings:\n",
    "valid_readings = list(filter(lambda t: t is not None and t >= 0,sensor_data))\n",
    "\n",
    "# Convert C to F.\n",
    "fahrenheit = list(map(lambda t: round(( t * 9/5) + 32,2), valid_readings))\n",
    "\n",
    "print(\" Valid Readings ( Fahrenheit):\",fahrenheit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31cbe5-3204-4667-9ec9-ad543ebf12d6",
   "metadata": {},
   "source": [
    "## ETL Pipeline - Sales Data Cleaner\n",
    "### Real-World Scenario\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd24a6f0-05d1-4afc-9b8e-3a4256580c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def extract_data(filepath):\n",
    "    \"\"\" Extract: Read CSV into a list of dicts \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return list(reader)\n",
    "        \n",
    "def transform_data(records):\n",
    "    \"\"\" Transform: Clean and process the data \"\"\"\n",
    "    # step 1 - Normalize customer names\n",
    "    records = list(map(lambda r:{**r,\n",
    "    \"customer_name\": r[\"customer_name\"].strip().title(),\n",
    "    \"product\":r[\"product\"].strip().title(),\n",
    "    \"amount\":r[\"amount\"].strip()},records))\n",
    "\n",
    "# step 2 - Filter invalid rows (missing /zero amount)\n",
    "    records = list(filter(lambda r: r[\"amount\"] and float(r[\"amount\"]) > 0, records))\n",
    "\n",
    "# step 3 - Add 10% commission column  \n",
    "    for r in records:\n",
    "        amount = float(r[\"amount\"])\n",
    "        r[\"commission\"] = round(amount * 0.10, 2)\n",
    "\n",
    "        return records\n",
    "\n",
    "def load_data(records, output_path):\n",
    "    \"\"\" Load: write cleaned data to a new CSV \"\"\"\n",
    "    with open(output_path, 'w', newline='') as file:\n",
    "        fieldnames = [\"customer_name\",\"product\",\"amount\",\"commission\"]\n",
    "        writer = csv.DictWriter(file,fieldnames=filednames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "\n",
    "def etl_pipeline(input_file, output_file):\n",
    "    \"\"\" Run the full ETL pipelines \"\"\"\n",
    "    raw_data = extract_data(input_file)\n",
    "    cleaned_data = transform_data(raw_data)\n",
    "    load_data(cleaned_data, output_file)\n",
    "    print(f\" ETL complete:{len(cleaned_data)} valid rows written to {output_file}\")\n",
    "    \n",
    "    etl_pipeline(\"book1.csv\",\"cleaned_sales.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef178e21-f234-434a-b835-1242c43e02a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'product': 'Laptop', 'amount': '55000', 'commission': 5500.0}, {'name': 'Bob', 'product': 'Electronic', 'amount': '65000', 'commission': 6500.0}, {'name': 'Alice', 'product': 'Mobile', 'amount': '55000', 'commission': 5500.0}]\n"
     ]
    }
   ],
   "source": [
    "## Simple ETL Example - Sales Data Cleaning:\n",
    "\n",
    "sales_data = [\n",
    "    {\"name\": \"alice \",\"product\":\" laptop \",\"amount\":\"55000\"},\n",
    "    {\"name\": \"Bob \",\"product\":\" electronic \",\"amount\":\"65000\"},\n",
    "    {\"name\": \"alICE \",\"product\":\" Mobile \",\"amount\":\"55000\"}\n",
    "]\n",
    "\n",
    "# step 1 - clean the data using map()\n",
    "cleaned_data = list(map(lambda x: {\n",
    "    \"name\":x[\"name\"].strip().title(),\n",
    "    \"product\":x[\"product\"].strip().title(),\n",
    "    \"amount\":x[\"amount\"].strip().title()\n",
    "}, sales_data))\n",
    "\n",
    "# Step 2 - Remove invalid rows using filter()\n",
    "\n",
    "valid_sales = list(filter(lambda x:x[\"amount\"] and float(x[\"amount\"]) > 0, cleaned_data))\n",
    "\n",
    "# Step 3 - Add commission column (10%)\n",
    "for sale in valid_sales:\n",
    "    sale[\"commission\"] = round(float(sale[\"amount\"]) * 0.10 ,2)\n",
    "\n",
    "# Step 4 - print the result\n",
    "print(valid_sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051371a3-8c76-4e2a-8501-df4b72bc686d",
   "metadata": {},
   "source": [
    "### Microsoft style-Data Engineer Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f453a9-b55a-4fff-99d6-fd1cfa222f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data set: [{'name': 'Jay', 'dept': 'Data', 'salary': '8000'}, {'name': 'Ravi', 'dept': 'Data', 'salary': ''}, {'name': 'Meena', 'dept': 'Analytics', 'salary': '95000'}]\n",
      "Filter out employees with missing salary\n",
      "[{'name': 'Jay', 'dept': 'Data', 'salary': '8000'}, {'name': 'Meena', 'dept': 'Analytics', 'salary': '95000'}]\n",
      "Added New Column with Annual Bonus:\n",
      "[{'name': 'Jay', 'dept': 'Data', 'salary': '8000', 'annual_bonus': 800}, {'name': 'Meena', 'dept': 'Analytics', 'salary': '95000', 'annual_bonus': 9500}]\n"
     ]
    }
   ],
   "source": [
    "# Scenario:\n",
    "## you're given a list of employee details from multiple systems.\n",
    "\n",
    "# Given tasks \n",
    "# Clean the data - remove spaces and fix case (e.g,\"Jay\",\"Data\").\n",
    "# Filter out employees with missing salary.\n",
    "# Add a new column: \"annual_bonus\" = 0.1 * salary\n",
    "\n",
    "employees = [\n",
    "    {\"name\":\"jAy\",\"dept\":\"Data\",\"salary\":\"8000\"},\n",
    "    {\"name\":\"RAVI\",\"dept\":\"Data\",\"salary\":\" \"},\n",
    "    {\"name\":\"meena\",\"dept\":\"Analytics\",\"salary\":\"95000\"}\n",
    "]\n",
    "\n",
    "# Clean the data using map():\n",
    "\n",
    "cleaned_data = list(map(lambda x : {\n",
    "            \"name\":x[\"name\"].strip().capitalize(),\n",
    "            \"dept\":x[\"dept\"].strip().capitalize(),\n",
    "            \"salary\":x[\"salary\"].strip().capitalize()\n",
    "},employees))\n",
    "print(\"Cleaned Data set:\",cleaned_data)\n",
    "\n",
    "# step 2: Filter out employees with missing salary\n",
    "\n",
    "print(\"Filter out employees with missing salary\")\n",
    "missing_salary = list(filter(lambda x : x[\"salary\"] and float(x[\"salary\"]) > 1, cleaned_data))\n",
    "print(missing_salary)\n",
    "\n",
    "# step 3: Add new column: \" annual_bonus\" = 0.1 * salary\n",
    "\n",
    "print(\"Added New Column with Annual Bonus:\")\n",
    "for sale in missing_salary:\n",
    "    sale[\"annual_bonus\"] = round(float(sale[\"salary\"]) * 0.1 )\n",
    "print(missing_salary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2781aef-bcdd-4df0-988e-3e0632e8b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned_data: [{'city': 'Seattle', 'temp_f': 53.6}, {'city': 'Mumbai', 'temp_f': 91.4}]\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Weather Data Transformation\n",
    "'''\n",
    "Scenario: A weather API gives temperatures in Celsius.\n",
    "you need to convert them to fehrenheit and remove invalid records.\n",
    "\n",
    "Tasks to complete:\n",
    "\n",
    "-> Convert temp_c -> temp_f = (temp_c * 9/5) + 32.\n",
    "-> Remove any records with missing temperature.\n",
    "\n",
    "'''\n",
    "\n",
    "weather = [\n",
    "    {\"city\":\"Seattle\",\"temp_c\":12},\n",
    "    {\"city\":\"Mumbai\",\"temp_c\":33},\n",
    "    {\"city\":\"Paris\",\"temp_c\":None}\n",
    "]\n",
    "\n",
    "# Remove the records with missing temperature.\n",
    "valid_weather = list(filter(lambda x: x[\"temp_c\"] is not None, weather))\n",
    "\n",
    "# Convert Celsius -> Fahrenheit\n",
    "cleaned_data = list(map(lambda x:\n",
    "{\n",
    "    \"city\": x[\"city\"].title(),\n",
    "    \"temp_f\":round((float(x[\"temp_c\"]) * 9/5) + 32,1)}, valid_weather))\n",
    "print(\"Cleaned_data:\", cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac327772-f85e-4221-9593-8cc4003497aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3: Data Transformation from Logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3879a190-c490-4446-8469-65ed725ebca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'north_total': 3937.5, 'south_updated': 3465.0, 'east_updated': 2992.5}\n"
     ]
    }
   ],
   "source": [
    "## Task 4: Revenue Summary\n",
    "'''\n",
    "Scenario:\n",
    "You get monthly sales from 3 regions\n",
    "\n",
    "north = [1200, 1300, 1250]\n",
    "south = [1100, 1050, 1150]\n",
    "east = [900, 950, 1000]\n",
    "\n",
    " Your task:\n",
    "1. Increase all numbers by 5% (price growth)\n",
    "2. Calculate total revenue for each region.\n",
    "\n",
    "'''\n",
    "\n",
    "north = [1200, 1300, 1250]\n",
    "south = [1100, 1050, 1150]\n",
    "east = [900, 950, 1000]\n",
    "\n",
    "# step 1: Increse by 5%\n",
    "north_updated = list(map(lambda x: round(x * 1.05, 2), north))\n",
    "south_updated = list(map(lambda x: round(x * 1.05, 2),south))\n",
    "east_updated = list(map(lambda x: round(x * 1.05, 2),east))\n",
    "\n",
    "# step 2: Calculate total per region\n",
    "totals = {\n",
    "    \"north_total\" : sum(north_updated),\n",
    "    \"south_updated\" :sum(south_updated),\n",
    "    \"east_updated\" :sum(east_updated)\n",
    "}\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6c442e-408c-4bdc-bf5b-ca32e6c13095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'total': 900}, {'name': 'Charlie', 'total': 1800}]\n"
     ]
    }
   ],
   "source": [
    "## Task 5: Identify High - value Customers.\n",
    "\n",
    "'''\n",
    "Scenario:\n",
    "Your Company tracks customers and their purchases.\n",
    "'''\n",
    "\n",
    "customers = [\n",
    "    {\"name\":\"Alice\",\"purchases\":[200,300,400]},\n",
    "    {\"name\":\"Bob\",\"purchases\":[100,200,300]},\n",
    "    {\"name\":\"Charlie\",\"purchases\":[500,600,700]}\n",
    "]\n",
    "\n",
    "''' \n",
    "Your Task:\n",
    "1. Calculate total purchase per customer.\n",
    "2. Filter only customers who spent more then 800\n",
    "'''\n",
    "\n",
    "# step 1: Calculate total per customer\n",
    "totals = list(map(lambda c: {\"name\":c[\"name\"],\"total\":sum(c[\"purchases\"])},customers))\n",
    "\n",
    "# step 2: Filter high-value customers:\n",
    "high_value = list(filter(lambda c: c[\"total\"] > 800, totals))\n",
    "\n",
    "print(high_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd8400d-b27b-4639-aea5-203425b678de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'email': 'alice@gmail.com', 'age': 56}, {'name': 'Charlie', 'email': 'charlie@example.com', 'age': 34}]\n"
     ]
    }
   ],
   "source": [
    "# Date 25/10/2025.\n",
    "''''\n",
    "Scenario 1:\n",
    "\n",
    "Problems: \n",
    "You receive daily files from different source. Some columns need transformation,\n",
    "and some rows need filtering.\n",
    "\n",
    "Task 1:\n",
    "-> Convert all email addresses to lowercase.\n",
    "-> Keep only rows where age > 18.\n",
    "-> Extract domains from email addresses.\n",
    "\n",
    "'''\n",
    "\n",
    "Data = [\n",
    "    {\"name\":\"Alice\",\"email\":\"ALICE@gmail.com\",\"age\":56},\n",
    "    {\"name\":\"Bob\",\"email\":\"BOB@gmail.com\",\"age\":17},\n",
    "    {\"name\":\"Charlie\",\"email\":\"charlie@example.com\",\"age\":34}\n",
    "]\n",
    "\n",
    "# 1. Filter adults only \n",
    "adults = list(filter(lambda x : x['age'] > 18,Data))\n",
    "\n",
    "# 2. Normalize all the emails addresses to lowercase.\n",
    "email_addresses = list(map(lambda x : {**x, \"email\": x[\"email\"].lower()},adults))\n",
    "\n",
    "print(email_addresses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0bea98-48fc-42ce-b4e0-e78c310e39dc",
   "metadata": {},
   "source": [
    "#### normalized = list(map(lambda x: {**x, \"email\": x['email'].lower()}, adults)). what is **x means here.\n",
    "\n",
    "Ah! This is an important Python concept often used in data engineering and automation. Letâ€™s break it down carefully.\n",
    "\n",
    "The line you mentioned:\n",
    "\n",
    "```python\n",
    "normalized = list(map(lambda x: {**x, \"email\": x['email'].lower()}, adults))\n",
    "```\n",
    "\n",
    "Hereâ€™s what each part means:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. `x`**\n",
    "\n",
    "* `x` represents **each element in the `adults` list**.\n",
    "* In our example, `adults` is a list of dictionaries:\n",
    "\n",
    "```python\n",
    "adults = [\n",
    "    {\"name\": \"Alice\", \"email\": \"ALICE@Example.com\", \"age\": 25},\n",
    "    {\"name\": \"Charlie\", \"email\": \"charlie@example.com\", \"age\": 30}\n",
    "]\n",
    "```\n",
    "\n",
    "* So, `x` will be:\n",
    "\n",
    "```python\n",
    "{\"name\": \"Alice\", \"email\": \"ALICE@Example.com\", \"age\": 25}  # first iteration\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `{**x, \"email\": x['email'].lower()}`\n",
    "\n",
    "This is **dictionary unpacking**.\n",
    "\n",
    "* `**x` takes all key-value pairs from dictionary `x` and **copies them into a new dictionary**.\n",
    "* Then, `\"email\": x['email'].lower()` **overwrites the `email` key** with the lowercase version.\n",
    "\n",
    "So for Alice:\n",
    "\n",
    "```python\n",
    "x = {\"name\": \"Alice\", \"email\": \"ALICE@Example.com\", \"age\": 25}\n",
    "\n",
    "# {**x, \"email\": x['email'].lower()} \n",
    "# becomes\n",
    "{\"name\": \"Alice\", \"email\": \"alice@example.com\", \"age\": 25}\n",
    "```\n",
    "\n",
    "âœ… Essentially, it **creates a new dictionary based on the old one but updates only the email field**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Why we use `**x` instead of modifying `x` directly**\n",
    "\n",
    "* `x` comes from the `adults` list. Modifying it directly could **change the original data** (mutability issues).\n",
    "* Using `{**x, ...}` ensures **a new dictionary is created**, leaving the original list unchanged.\n",
    "* This is a functional programming style, common in MAANG interviews.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can draw a **small visual flow diagram** showing how `map()` + `lambda` + `**x` transforms the dictionary step by stepâ€”itâ€™s super helpful for interviews.\n",
    "\n",
    "Do you want me to do that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06810ec-a4a9-47b3-8e49-b0f40f59753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmail.com', 'example.com']\n"
     ]
    }
   ],
   "source": [
    "# Extract email address\n",
    "domains = list(map(lambda x : x['email'].split('@')[1], email_addresses))\n",
    "print(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cebd8b7-2fa5-433d-8f14-9ab123b4c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERROR: Code 500 - Internal Server Error', 'ERROR: Code 404 - Not Found']\n",
      "['Internal', 'Not']\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Scenario 2: Log File Automation:\n",
    "Problem:\n",
    "you have server logs in a list of strings. you want to\"\n",
    "--> Keep only error logs.\n",
    "--> Extract the error codes automatically.\n",
    "\n",
    "'''\n",
    "\n",
    "log = [\n",
    "    \"INFO: Server started\",\n",
    "    \"ERROR: Code 500 - Internal Server Error\",\n",
    "    \"WARNING: Low memory\",\n",
    "    \"ERROR: Code 404 - Not Found\"\n",
    "]\n",
    "\n",
    "#  Filter error logs\n",
    "error_logs = list(filter(lambda x : \"ERROR\" in x, log))\n",
    "\n",
    "# Extract error code\n",
    "error_codes = list(map(lambda x: x.split()[4], error_logs))\n",
    "\n",
    "print(error_logs)\n",
    "print(error_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc46d1b-6e95-4009-9d5e-8f1360545c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 2, 'amount': 15000}, {'id': 3, 'amount': 25000}]\n",
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Scenario 3: Automated Notification for High-value Transactions\n",
    "\n",
    "Problem: \n",
    "you have a list of transactions. \n",
    "you want to automatically identify high-value transactions(>$10,000) to trigger alerts.\n",
    "\n",
    "'''\n",
    "\n",
    "transactions = [\n",
    "    {\"id\":1,\"amount\":5000},\n",
    "    {\"id\":2,\"amount\":15000},\n",
    "    {\"id\":3,\"amount\":25000}\n",
    "]\n",
    "\n",
    "# Filter high-value transactions.\n",
    "high_value = list(filter(lambda x : x['amount'] > 10000,transactions))\n",
    "\n",
    "# Extract transactions IDs for notifications\n",
    "notify_ids = list(map(lambda x: x['id'], high_value))\n",
    "\n",
    "print(high_value)\n",
    "print(notify_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff32149c-f283-44a3-829c-b497d63c967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.25, 0.5, 0.75, 1.0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Scenario 4: Batch Data Transformation\n",
    "\n",
    "Problem:\n",
    "You need to normalize numerical data for machine learning or analytics.\n",
    "\n",
    "'''\n",
    "raw_numbers = [10,20,30,40,50]\n",
    "\n",
    "# Scale numbers between 0 and 1\n",
    "min_val,max_val = min(raw_numbers),max(raw_numbers)\n",
    "scaled = list(map(lambda x : (x - min_val) / (max_val - min_val), raw_numbers))\n",
    "\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70d9c2-7788-40ca-b12a-54af24553463",
   "metadata": {},
   "source": [
    "Formula for Min-Max Scaling\n",
    "\n",
    "scaledÂ value = ð‘¥ âˆ’ min / max âˆ’ min.\n",
    "\n",
    "This formula converts all numbers into a range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edbb046b-c8eb-40f2-baf3-468775f3d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000, 0, 10000]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Automated Financial Report Cleanup:\n",
    "Use Case: Clean up large transaction logs before storing in a database.\n",
    "\n",
    "'''\n",
    "transactions = [ \n",
    "    {\"amount\":5000,\"currency\":\"usd\"},\n",
    "    {\"amount\":0,\"currency\":\"usd\"},\n",
    "    {\"amount\":10000,\"currency\":\"usd\"}\n",
    "]\n",
    "\n",
    "valid = list(filter(lambda x : x[\"amount\"] > 1, transactions))\n",
    "totals = list(map(lambda x : x[\"amount\"], transactions))\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a49eeb-e9cc-4b79-a019-07c1944ebcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alice', 'alice123@gmail.com'), ('Surya', 'surya123@gmail.com'), ('Ram', 'ram@gmail.com'), ('Rajan', 'rajan@outlook.com')]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Scenario 1: Data Cleaning Automation\n",
    "\n",
    "Use Case : A Data Engineer is processing customer data where some phone numbers or emails are invalid. \n",
    "you need to automatically clean and standardize them.\n",
    "\n",
    "'''\n",
    "\n",
    "# input data:\n",
    "Customers = [\n",
    "    {\"name\":\"Alice\",\"email\":\"alice123@gmail.com\"},\n",
    "    {\"name\":\"Surya\",\"email\":\"Surya123@gmail.com\"},\n",
    "    {\"name\":\"Ram\",\"email\":\"ram@gmail.com\"},\n",
    "    {\"name\":\"Rajan\",\"email\":\"rajan@outlook.com\"}\n",
    "]\n",
    "\n",
    "# clean valid emails only using filter and lambda\n",
    "valid_customers = list(filter(lambda x: '@' in x['email'] and '.' in x['email'],Customers))\n",
    "\n",
    "# Extract clean names and emails using map\n",
    "cleaned_data = list(map(lambda x: (x['name'].title(), x['email'].lower()),valid_customers))\n",
    "\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65163fc7-de3a-4f7b-af55-891943598744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Database connection failed', 'API timeout']\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Scenario 3: Log File Processing\n",
    "\n",
    "Use Case: you are automating the processing of server logs to filter out only the error messages.\n",
    "\n",
    "'''\n",
    "\n",
    "logs = [\n",
    "    \"INFO: Service started\",\n",
    "    \"WARNING: Low disk space\",\n",
    "    \"ERROR: Database connection failed\",\n",
    "    \"INFO: Request processed\",\n",
    "    \"ERROR: API timeout\"\n",
    "]\n",
    "\n",
    "# Filter only errors\n",
    "error_logs = list(filter(lambda log:\"ERROR\" in log, logs))\n",
    "\n",
    "# Extract only the error message part using map\n",
    "error_message = list(map(lambda log: log.split(\":\")[1].strip(), error_logs))\n",
    "\n",
    "print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea6499b-ca28-4c50-9d54-6dd0e47afaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221.0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Scenario 4: IoT or Sensor Data Filtering\n",
    "Use Case:\n",
    "A pipeline receives temperature data from IoT sensors. \n",
    "you must filter faulty reading(e.g., < 0 or >100 C).\n",
    "\n",
    "'''\n",
    "sensor_readings = [25,30,-5,105,45,60]\n",
    "\n",
    "valid_readings = list(filter(lambda x : 0 <= x >= 100, sensor_readings))\n",
    "\n",
    "# Convert to Fahrenheit\n",
    "to_fahrenheit = list(map(lambda x : (x * 9/5 ) + 32, valid_readings))\n",
    "\n",
    "print(to_fahrenheit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0fc478-47c5-4d58-bc52-effc16a29f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world', 'data engineer', 'microsoft ai']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Scenario 5: File Automation( AI Data Preprocessing)\n",
    "Before sending text data to an AI Model, \n",
    "automate preprocessing like trimming whitespaces and converting to lowercase.\n",
    "\n",
    "'''\n",
    "\n",
    "sentences = [\" Hello World \", \" DATA Engineer \", \" Microsoft AI \"]\n",
    "\n",
    "# Clean sentences\n",
    "cleaned = list(map(lambda s : s.strip().lower(), sentences))\n",
    "\n",
    "# Filter out empty strings\n",
    "filtered = list(filter(lambda s : len(s) > 0, cleaned))\n",
    "\n",
    "print(filtered)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb30d916-1c7d-4a0f-a3e9-fc41c563c434",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3232569716.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    return {\"cleaned_texts:\" filtered}\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Text Preprocessing API (AI/ML Use Case)\n",
    "Scenario:\n",
    "Before feeding text data into an ML model, you must clean it via an API.\n",
    "\n",
    "Goal:\n",
    "-> Removes extra spaces\n",
    "-> Converts to lowercase\n",
    "-> Filters empty strings\n",
    "\n",
    "'''\n",
    "\n",
    "from fastapi import FastAPI\n",
    "@app.post(\"/clean_text\")\n",
    "def clean_text(data:List[str]):\n",
    "    cleaned = list(map(lambda s: s.strip().lower(), data))\n",
    "    filtered = list(filter(lambda s: len(s) > 0, cleaned))\n",
    "    return {\"cleaned_texts:\" filtered}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13b34e-f293-4618-982f-99fcc1d43e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
